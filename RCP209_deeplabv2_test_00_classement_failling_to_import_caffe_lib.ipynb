{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nyluje/RCP209DeeplabExperiment/blob/main/RCP209_deeplabv2_test_00_classement_failling_to_import_caffe_lib.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experimentation of Deeplab v2 in Google Colab\n",
        "\n",
        "## Introduction\n",
        "\n",
        "For academic purpose, this notebook is meant to experiment Deeplab v2 as described in [Liang-Chieh Chen web page](http://liangchiehchen.com/projects/DeepLab.html) through a Notebook running in Google Colab. The page gives direction to the code located at this [repository](https://bitbucket.org/aquariusjay/deeplab-public-ver2/src/master/)."
      ],
      "metadata": {
        "id": "cmuWF-aVb3Bb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IR2O9TlPTIpI",
        "outputId": "d371a132-b1c5-4b84-ab24-d935b4d5d66a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'deeplabv2'...\n",
            "Receiving objects: 100% (765/765), 7.11 MiB | 26.21 MiB/s, done.\n",
            "Resolving deltas: 100% (173/173), done.\n"
          ]
        }
      ],
      "source": [
        "!mkdir deeplabv2\n",
        "!git clone https://bitbucket.org/aquariusjay/deeplab-public-ver2/src/master/ deeplabv2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Caffe lib installation\n",
        "\n",
        "The caffe lib needs to be installed in Google Colab in order to use the code. \n",
        "\n",
        "Caffe lib installation in Google Colab reproduces the steps explained in this [Medium article](https://filip-drapejkowski.medium.com/caffe-in-google-colab-2021-2d730989c849) and [its Google Colab implementation example](https://colab.research.google.com/github/Huxwell/caffe-colab/blob/main/caffe_details.ipynb#scrollTo=iDt9JEiq5qHd) (comments have been added ahead of code chunks duplicated from this work).\n",
        "\n"
      ],
      "metadata": {
        "id": "cK2KtYXNbbIc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HheSRB1T8OA",
        "outputId": "53a75441-fd02-4d4d-93dd-d112a394fdd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'caffe'...\n",
            "remote: Enumerating objects: 65274, done.\u001b[K\n",
            "remote: Total 65274 (delta 0), reused 0 (delta 0), pack-reused 65274\u001b[K\n",
            "Receiving objects: 100% (65274/65274), 74.14 MiB | 22.76 MiB/s, done.\n",
            "Resolving deltas: 100% (41249/41249), done.\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  libgflags2.2\n",
            "0 upgraded, 1 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 72.4 kB of archives.\n",
            "After this operation, 312 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libgflags2.2 amd64 2.2.1-1 [72.4 kB]\n",
            "Fetched 72.4 kB in 0s (210 kB/s)\n",
            "Selecting previously unselected package libgflags2.2.\n",
            "(Reading database ... 155335 files and directories currently installed.)\n",
            "Preparing to unpack .../libgflags2.2_2.2.1-1_amd64.deb ...\n",
            "Unpacking libgflags2.2 (2.2.1-1) ...\n",
            "Setting up libgflags2.2 (2.2.1-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  libgflags-dev\n",
            "0 upgraded, 1 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 86.1 kB of archives.\n",
            "After this operation, 598 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libgflags-dev amd64 2.2.1-1 [86.1 kB]\n",
            "Fetched 86.1 kB in 0s (240 kB/s)\n",
            "Selecting previously unselected package libgflags-dev.\n",
            "(Reading database ... 155342 files and directories currently installed.)\n",
            "Preparing to unpack .../libgflags-dev_2.2.1-1_amd64.deb ...\n",
            "Unpacking libgflags-dev (2.2.1-1) ...\n",
            "Setting up libgflags-dev (2.2.1-1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libgoogle-glog0v5\n",
            "The following NEW packages will be installed:\n",
            "  libgoogle-glog-dev libgoogle-glog0v5\n",
            "0 upgraded, 2 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 124 kB of archives.\n",
            "After this operation, 508 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libgoogle-glog0v5 amd64 0.3.5-1 [50.5 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libgoogle-glog-dev amd64 0.3.5-1 [73.8 kB]\n",
            "Fetched 124 kB in 0s (268 kB/s)\n",
            "Selecting previously unselected package libgoogle-glog0v5.\n",
            "(Reading database ... 155360 files and directories currently installed.)\n",
            "Preparing to unpack .../libgoogle-glog0v5_0.3.5-1_amd64.deb ...\n",
            "Unpacking libgoogle-glog0v5 (0.3.5-1) ...\n",
            "Selecting previously unselected package libgoogle-glog-dev.\n",
            "Preparing to unpack .../libgoogle-glog-dev_0.3.5-1_amd64.deb ...\n",
            "Unpacking libgoogle-glog-dev (0.3.5-1) ...\n",
            "Setting up libgoogle-glog0v5 (0.3.5-1) ...\n",
            "Setting up libgoogle-glog-dev (0.3.5-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libhdf5-100 is already the newest version (1.10.0-patch1+docs-4).\n",
            "libhdf5-100 set to manually installed.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  libhdf5-serial-dev\n",
            "0 upgraded, 1 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 2,898 B of archives.\n",
            "After this operation, 37.9 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libhdf5-serial-dev all 1.10.0-patch1+docs-4 [2,898 B]\n",
            "Fetched 2,898 B in 0s (27.4 kB/s)\n",
            "Selecting previously unselected package libhdf5-serial-dev.\n",
            "(Reading database ... 155378 files and directories currently installed.)\n",
            "Preparing to unpack .../libhdf5-serial-dev_1.10.0-patch1+docs-4_all.deb ...\n",
            "Unpacking libhdf5-serial-dev (1.10.0-patch1+docs-4) ...\n",
            "Setting up libhdf5-serial-dev (1.10.0-patch1+docs-4) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libhdf5-dev is already the newest version (1.10.0-patch1+docs-4).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libhdf5-cpp-100 is already the newest version (1.10.0-patch1+docs-4).\n",
            "libhdf5-cpp-100 set to manually installed.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "protobuf-compiler is already the newest version (3.0.0-9.1ubuntu1).\n",
            "The following NEW packages will be installed:\n",
            "  libprotobuf-dev libprotobuf-lite10\n",
            "0 upgraded, 2 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 1,056 kB of archives.\n",
            "After this operation, 8,482 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libprotobuf-lite10 amd64 3.0.0-9.1ubuntu1 [97.7 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 libprotobuf-dev amd64 3.0.0-9.1ubuntu1 [959 kB]\n",
            "Fetched 1,056 kB in 1s (1,430 kB/s)\n",
            "Selecting previously unselected package libprotobuf-lite10:amd64.\n",
            "(Reading database ... 155382 files and directories currently installed.)\n",
            "Preparing to unpack .../libprotobuf-lite10_3.0.0-9.1ubuntu1_amd64.deb ...\n",
            "Unpacking libprotobuf-lite10:amd64 (3.0.0-9.1ubuntu1) ...\n",
            "Selecting previously unselected package libprotobuf-dev:amd64.\n",
            "Preparing to unpack .../libprotobuf-dev_3.0.0-9.1ubuntu1_amd64.deb ...\n",
            "Unpacking libprotobuf-dev:amd64 (3.0.0-9.1ubuntu1) ...\n",
            "Setting up libprotobuf-lite10:amd64 (3.0.0-9.1ubuntu1) ...\n",
            "Setting up libprotobuf-dev:amd64 (3.0.0-9.1ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# code duplicated from https://colab.research.google.com/github/Huxwell/caffe-colab/blob/main/caffe_details.ipynb#scrollTo=iDt9JEiq5qHd\n",
        "\n",
        "\n",
        "TARGET_DIR=\"/content\"\n",
        "!cd $TARGET_DIR\n",
        "!git clone https://github.com/BVLC/caffe.git\n",
        "!git reset --hard 9b891540183ddc834a02b2bd81b31afae71b2153 \n",
        "!apt-get install libgflags2.2 \n",
        "!apt-get install libgflags-dev\n",
        "!apt-get install libgoogle-glog-dev\n",
        "!apt-get install libhdf5-100\n",
        "!apt-get install libhdf5-serial-dev\n",
        "!apt-get install libhdf5-dev\n",
        "!apt-get install libhdf5-cpp-100\n",
        "!apt-get install libprotobuf-dev protobuf-compiler\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# code duplicated from https://colab.research.google.com/github/Huxwell/caffe-colab/blob/main/caffe_details.ipynb#scrollTo=iDt9JEiq5qHd\n",
        "\n",
        "!find /usr -iname \"*hdf5.so\"\n",
        "# got: /usr/lib/x86_64-linux-gnu/hdf5/serial\n",
        "!find /usr -iname \"*hdf5_hl.so\"\n",
        "!ln -s /usr/lib/x86_64-linux-gnu/libhdf5_serial.so /usr/lib/x86_64-linux-gnu/libhdf5.so\n",
        "!ln -s /usr/lib/x86_64-linux-gnu/libhdf5_serial_hl.so /usr/lib/x86_64-linux-gnu/libhdf5_hl.so\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMJWeEVBPDsL",
        "outputId": "b1cfd73e-c09b-421b-f477-e342179649fa"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/lib/x86_64-linux-gnu/hdf5/serial/libhdf5.so\n",
            "/usr/lib/x86_64-linux-gnu/hdf5/serial/libhdf5_hl.so\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# code duplicated from https://colab.research.google.com/github/Huxwell/caffe-colab/blob/main/caffe_details.ipynb#scrollTo=iDt9JEiq5qHd\n",
        "\n",
        "#!find /usr -iname \"*hdf5.h*\" # got:\n",
        "# /usr/include/hdf5/serial/hdf5.h \n",
        "# /usr/include/opencv2/flann/hdf5.h\n",
        "# Let's try the first one.\n",
        "%env CPATH=/usr/include/hdf5/serial/\n",
        "#fatal error: hdf5.h: No such file or directory\n",
        "\n",
        "!apt-get install libleveldb-dev\n",
        "!apt-get install libgflags-dev libgoogle-glog-dev liblmdb-dev\n",
        "!apt-get install libsnappy-dev\n",
        "\n",
        "!echo $CPATH\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_ekoSd0PFem",
        "outputId": "82d4b608-c70e-43d7-dbdd-7f49636bc11a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: CPATH=/usr/include/hdf5/serial/\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libleveldb1v5\n",
            "Suggested packages:\n",
            "  leveldb-doc\n",
            "The following NEW packages will be installed:\n",
            "  libleveldb-dev libleveldb1v5\n",
            "0 upgraded, 2 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 313 kB of archives.\n",
            "After this operation, 1,336 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libleveldb1v5 amd64 1.20-2 [136 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 libleveldb-dev amd64 1.20-2 [177 kB]\n",
            "Fetched 313 kB in 1s (547 kB/s)\n",
            "Selecting previously unselected package libleveldb1v5:amd64.\n",
            "(Reading database ... 155503 files and directories currently installed.)\n",
            "Preparing to unpack .../libleveldb1v5_1.20-2_amd64.deb ...\n",
            "Unpacking libleveldb1v5:amd64 (1.20-2) ...\n",
            "Selecting previously unselected package libleveldb-dev:amd64.\n",
            "Preparing to unpack .../libleveldb-dev_1.20-2_amd64.deb ...\n",
            "Unpacking libleveldb-dev:amd64 (1.20-2) ...\n",
            "Setting up libleveldb1v5:amd64 (1.20-2) ...\n",
            "Setting up libleveldb-dev:amd64 (1.20-2) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libgflags-dev is already the newest version (2.2.1-1).\n",
            "libgoogle-glog-dev is already the newest version (0.3.5-1).\n",
            "The following NEW packages will be installed:\n",
            "  liblmdb-dev liblmdb0 lmdb-doc\n",
            "0 upgraded, 3 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 380 kB of archives.\n",
            "After this operation, 2,707 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 liblmdb0 amd64 0.9.21-1ubuntu0.1 [44.6 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 liblmdb-dev amd64 0.9.21-1ubuntu0.1 [59.6 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 lmdb-doc all 0.9.21-1ubuntu0.1 [276 kB]\n",
            "Fetched 380 kB in 1s (623 kB/s)\n",
            "Selecting previously unselected package liblmdb0:amd64.\n",
            "(Reading database ... 155531 files and directories currently installed.)\n",
            "Preparing to unpack .../liblmdb0_0.9.21-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking liblmdb0:amd64 (0.9.21-1ubuntu0.1) ...\n",
            "Selecting previously unselected package liblmdb-dev:amd64.\n",
            "Preparing to unpack .../liblmdb-dev_0.9.21-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking liblmdb-dev:amd64 (0.9.21-1ubuntu0.1) ...\n",
            "Selecting previously unselected package lmdb-doc.\n",
            "Preparing to unpack .../lmdb-doc_0.9.21-1ubuntu0.1_all.deb ...\n",
            "Unpacking lmdb-doc (0.9.21-1ubuntu0.1) ...\n",
            "Setting up liblmdb0:amd64 (0.9.21-1ubuntu0.1) ...\n",
            "Setting up liblmdb-dev:amd64 (0.9.21-1ubuntu0.1) ...\n",
            "Setting up lmdb-doc (0.9.21-1ubuntu0.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  libsnappy-dev\n",
            "0 upgraded, 1 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 27.2 kB of archives.\n",
            "After this operation, 108 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsnappy-dev amd64 1.1.7-1 [27.2 kB]\n",
            "Fetched 27.2 kB in 0s (640 kB/s)\n",
            "Selecting previously unselected package libsnappy-dev:amd64.\n",
            "(Reading database ... 155766 files and directories currently installed.)\n",
            "Preparing to unpack .../libsnappy-dev_1.1.7-1_amd64.deb ...\n",
            "Unpacking libsnappy-dev:amd64 (1.1.7-1) ...\n",
            "Setting up libsnappy-dev:amd64 (1.1.7-1) ...\n",
            "/usr/include/hdf5/serial/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# code duplicated from https://colab.research.google.com/github/Huxwell/caffe-colab/blob/main/caffe_details.ipynb#scrollTo=iDt9JEiq5qHd\n",
        "\n",
        "%cd /content/caffe\n",
        "!ls\n",
        "!make clean\n",
        "!cp Makefile.config.example Makefile.config\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEEN2aTcRALV",
        "outputId": "a09645c4-dee2-40b9-8774-935bebb50ec7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/caffe\n",
            "caffe.cloc\t data\t   INSTALL.md\t\t    matlab     src\n",
            "cmake\t\t docker    LICENSE\t\t    models     tools\n",
            "CMakeLists.txt\t docs\t   Makefile\t\t    python\n",
            "CONTRIBUTING.md  examples  Makefile.config\t    README.md\n",
            "CONTRIBUTORS.md  include   Makefile.config.example  scripts\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*THE FOLLOWING PART WAS ADDED TO TRY TO SOLVE \"Import \"caffe\" could not be resolved\" encountered in section Classification: Instant Recognition with Caffe (deeplab v2 example 00-classification)*"
      ],
      "metadata": {
        "id": "uJmCNP7GBCPw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!sed -i 's/PYTHON_INCLUDE := \\/usr\\/include\\/python2.7 \\\\/# PYTHON_INCLUDE := \\/usr\\/include\\/python2.7 \\\\/' Makefile.config \n",
        "!sed -i 's/\\/usr\\/lib\\/python2.7\\/dist-packages\\/numpy\\/core\\/include/# \\/usr\\/lib\\/python2.7\\/dist-packages\\/numpy\\/core\\/include/' Makefile.config \n",
        "!sed -i 's/# PYTHON_INCLUDE := \\/usr\\/include\\/python3.5m \\\\/PYTHON_INCLUDE := \\/usr\\/include\\/python3.7m \\\\/' Makefile.config \n",
        "!sed -i 's/#                 \\/usr\\/lib\\/python3.5\\/dist-packages\\/numpy\\/core\\/include/                 \\/usr\\/local\\/lib\\/python3.7\\/dist-packages\\/numpy\\/core\\/include/' Makefile.config \n"
      ],
      "metadata": {
        "id": "Tg_e9M-q2yqt"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# code duplicated from https://colab.research.google.com/github/Huxwell/caffe-colab/blob/main/caffe_details.ipynb#scrollTo=iDt9JEiq5qHd\n",
        "\n",
        "!sed -i 's/-gencode arch=compute_20/#-gencode arch=compute_20/' Makefile.config #old cuda versions won't compile \n",
        "!sed -i 's/\\/usr\\/local\\/include/\\/usr\\/local\\/include \\/usr\\/include\\/hdf5\\/serial\\//'  Makefile.config #one of the 4 things needed to fix hdf5 issues\n",
        "!sed -i 's/# OPENCV_VERSION := 3/OPENCV_VERSION := 3/' Makefile.config #We actually use opencv 4.1.2, but it's similar enough to opencv 3.\n",
        "!sed -i 's/code=compute_61/code=compute_61 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_75,code=compute_75/' Makefile.config #support for new GPUs\n",
        "\n",
        "!make all -j 4 "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVIqjSdXR2_i",
        "outputId": "ef77a337-6a1f-4b93-aff1-1e8cdfd0b7b0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PROTOC src/caffe/proto/caffe.proto\n",
            "NVCC src/caffe/layers/batch_norm_layer.cu\n",
            "NVCC src/caffe/layers/lrn_layer.cu\n",
            "NVCC src/caffe/layers/cudnn_relu_layer.cu\n",
            "NVCC src/caffe/layers/cudnn_conv_layer.cu\n",
            "NVCC src/caffe/layers/accuracy_layer.cu\n",
            "NVCC src/caffe/layers/split_layer.cu\n",
            "NVCC src/caffe/layers/deconv_layer.cu\n",
            "NVCC src/caffe/layers/cudnn_lcn_layer.cu\n",
            "NVCC src/caffe/layers/recurrent_layer.cu\n",
            "NVCC src/caffe/layers/hdf5_output_layer.cu\n",
            "NVCC src/caffe/layers/exp_layer.cu\n",
            "NVCC src/caffe/layers/sigmoid_cross_entropy_loss_layer.cu\n",
            "NVCC src/caffe/layers/bias_layer.cu\n",
            "NVCC src/caffe/layers/cudnn_softmax_layer.cu\n",
            "NVCC src/caffe/layers/embed_layer.cu\n",
            "NVCC src/caffe/layers/power_layer.cu\n",
            "NVCC src/caffe/layers/euclidean_loss_layer.cu\n",
            "NVCC src/caffe/layers/dropout_layer.cu\n",
            "NVCC src/caffe/layers/contrastive_loss_layer.cu\n",
            "NVCC src/caffe/layers/swish_layer.cu\n",
            "NVCC src/caffe/layers/softmax_loss_layer.cu\n",
            "NVCC src/caffe/layers/pooling_layer.cu\n",
            "NVCC src/caffe/layers/crop_layer.cu\n",
            "NVCC src/caffe/layers/im2col_layer.cu\n",
            "NVCC src/caffe/layers/threshold_layer.cu\n",
            "NVCC src/caffe/layers/scale_layer.cu\n",
            "NVCC src/caffe/layers/concat_layer.cu\n",
            "NVCC src/caffe/layers/log_layer.cu\n",
            "NVCC src/caffe/layers/lstm_unit_layer.cu\n",
            "NVCC src/caffe/layers/absval_layer.cu\n",
            "NVCC src/caffe/layers/sigmoid_layer.cu\n",
            "NVCC src/caffe/layers/slice_layer.cu\n",
            "NVCC src/caffe/layers/conv_layer.cu\n",
            "NVCC src/caffe/layers/filter_layer.cu\n",
            "NVCC src/caffe/layers/cudnn_pooling_layer.cu\n",
            "NVCC src/caffe/layers/base_data_layer.cu\n",
            "NVCC src/caffe/layers/hdf5_data_layer.cu\n",
            "NVCC src/caffe/layers/inner_product_layer.cu\n",
            "NVCC src/caffe/layers/elu_layer.cu\n",
            "NVCC src/caffe/layers/softmax_layer.cu\n",
            "NVCC src/caffe/layers/relu_layer.cu\n",
            "NVCC src/caffe/layers/cudnn_deconv_layer.cu\n",
            "NVCC src/caffe/layers/clip_layer.cu\n",
            "NVCC src/caffe/layers/cudnn_sigmoid_layer.cu\n",
            "NVCC src/caffe/layers/mvn_layer.cu\n",
            "NVCC src/caffe/layers/bnll_layer.cu\n",
            "NVCC src/caffe/layers/cudnn_lrn_layer.cu\n",
            "NVCC src/caffe/layers/silence_layer.cu\n",
            "NVCC src/caffe/layers/cudnn_tanh_layer.cu\n",
            "NVCC src/caffe/layers/tanh_layer.cu\n",
            "NVCC src/caffe/layers/prelu_layer.cu\n",
            "NVCC src/caffe/layers/reduction_layer.cu\n",
            "NVCC src/caffe/layers/eltwise_layer.cu\n",
            "NVCC src/caffe/layers/tile_layer.cu\n",
            "NVCC src/caffe/layers/batch_reindex_layer.cu\n",
            "NVCC src/caffe/util/math_functions.cu\n",
            "In file included from \u001b[01m\u001b[Ksrc/caffe/util/math_functions.cu:1:0\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/cuda/include/math_functions.h:54:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"math_functions.h is an internal header file and must not be used directly.  This file will be removed in a future CUDA release.  Please use cuda_runtime_api.h or cuda_runtime.h instead.\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\n",
            " #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"math_functions.h is an internal header file and must not be used directly.  This file will be removed in a future CUDA release.  Please use cuda_runtime_api.h or cuda_runtime.h instead.\"\n",
            "  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[Ksrc/caffe/util/math_functions.cu:1:0\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/cuda/include/math_functions.h:54:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"math_functions.h is an internal header file and must not be used directly.  This file will be removed in a future CUDA release.  Please use cuda_runtime_api.h or cuda_runtime.h instead.\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\n",
            " #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"math_functions.h is an internal header file and must not be used directly.  This file will be removed in a future CUDA release.  Please use cuda_runtime_api.h or cuda_runtime.h instead.\"\n",
            "  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "NVCC src/caffe/util/im2col.cu\n",
            "NVCC src/caffe/solvers/sgd_solver.cu\n",
            "NVCC src/caffe/solvers/adagrad_solver.cu\n",
            "In file included from src/caffe/util/math_functions.cu:1:0:\n",
            "/usr/local/cuda/include/math_functions.h:54:2: warning: #warning \"math_functions.h is an internal header file and must not be used directly.  This file will be removed in a future CUDA release.  Please use cuda_runtime_api.h or cuda_runtime.h instead.\" [-Wcpp]\n",
            " #warning \"math_functions.h is an internal header file and must not be used directly.  This file will be removed in a future CUDA release.  Please use cuda_runtime_api.h or cuda_runtime.h instead.\"\n",
            "  ^~~~~~~\n",
            "In file included from src/caffe/util/math_functions.cu:1:0:\n",
            "/usr/local/cuda/include/math_functions.h:54:2: warning: #warning \"math_functions.h is an internal header file and must not be used directly.  This file will be removed in a future CUDA release.  Please use cuda_runtime_api.h or cuda_runtime.h instead.\" [-Wcpp]\n",
            " #warning \"math_functions.h is an internal header file and must not be used directly.  This file will be removed in a future CUDA release.  Please use cuda_runtime_api.h or cuda_runtime.h instead.\"\n",
            "  ^~~~~~~\n",
            "NVCC src/caffe/solvers/adam_solver.cu\n",
            "NVCC src/caffe/solvers/nesterov_solver.cu\n",
            "NVCC src/caffe/solvers/rmsprop_solver.cu\n",
            "NVCC src/caffe/solvers/adadelta_solver.cu\n",
            "CXX tools/upgrade_net_proto_text.cpp\n",
            "CXX tools/upgrade_solver_proto_text.cpp\n",
            "CXX tools/caffe.cpp\n",
            "CXX tools/compute_image_mean.cpp\n",
            "CXX tools/extract_features.cpp\n",
            "CXX tools/upgrade_net_proto_binary.cpp\n",
            "CXX tools/convert_imageset.cpp\n",
            "CXX examples/mnist/convert_mnist_data.cpp\n",
            "CXX examples/cifar10/convert_cifar_data.cpp\n",
            "CXX examples/cpp_classification/classification.cpp\n",
            "CXX examples/siamese/convert_mnist_siamese_data.cpp\n",
            "CXX .build_release/src/caffe/proto/caffe.pb.cc\n",
            "CXX src/caffe/layer_factory.cpp\n",
            "CXX src/caffe/internal_thread.cpp\n",
            "CXX src/caffe/data_transformer.cpp\n",
            "CXX src/caffe/solver.cpp\n",
            "CXX src/caffe/syncedmem.cpp\n",
            "CXX src/caffe/layers/prelu_layer.cpp\n",
            "CXX src/caffe/layers/scale_layer.cpp\n",
            "CXX src/caffe/layers/slice_layer.cpp\n",
            "CXX src/caffe/layers/batch_reindex_layer.cpp\n",
            "CXX src/caffe/layers/loss_layer.cpp\n",
            "CXX src/caffe/layers/image_data_layer.cpp\n",
            "CXX src/caffe/layers/cudnn_tanh_layer.cpp\n",
            "CXX src/caffe/layers/rnn_layer.cpp\n",
            "CXX src/caffe/layers/sigmoid_cross_entropy_loss_layer.cpp\n",
            "CXX src/caffe/layers/threshold_layer.cpp\n",
            "CXX src/caffe/layers/absval_layer.cpp\n",
            "CXX src/caffe/layers/tanh_layer.cpp\n",
            "CXX src/caffe/layers/cudnn_lcn_layer.cpp\n",
            "CXX src/caffe/layers/tile_layer.cpp\n",
            "CXX src/caffe/layers/cudnn_softmax_layer.cpp\n",
            "CXX src/caffe/layers/split_layer.cpp\n",
            "CXX src/caffe/layers/lstm_unit_layer.cpp\n",
            "CXX src/caffe/layers/flatten_layer.cpp\n",
            "CXX src/caffe/layers/swish_layer.cpp\n",
            "CXX src/caffe/layers/dropout_layer.cpp\n",
            "CXX src/caffe/layers/lstm_layer.cpp\n",
            "CXX src/caffe/layers/conv_layer.cpp\n",
            "CXX src/caffe/layers/inner_product_layer.cpp\n",
            "CXX src/caffe/layers/clip_layer.cpp\n",
            "CXX src/caffe/layers/batch_norm_layer.cpp\n",
            "CXX src/caffe/layers/hdf5_output_layer.cpp\n",
            "CXX src/caffe/layers/base_conv_layer.cpp\n",
            "CXX src/caffe/layers/data_layer.cpp\n",
            "CXX src/caffe/layers/exp_layer.cpp\n",
            "CXX src/caffe/layers/eltwise_layer.cpp\n",
            "CXX src/caffe/layers/reduction_layer.cpp\n",
            "CXX src/caffe/layers/relu_layer.cpp\n",
            "CXX src/caffe/layers/dummy_data_layer.cpp\n",
            "CXX src/caffe/layers/softmax_layer.cpp\n",
            "CXX src/caffe/layers/cudnn_sigmoid_layer.cpp\n",
            "CXX src/caffe/layers/im2col_layer.cpp\n",
            "CXX src/caffe/layers/memory_data_layer.cpp\n",
            "CXX src/caffe/layers/spp_layer.cpp\n",
            "CXX src/caffe/layers/cudnn_relu_layer.cpp\n",
            "CXX src/caffe/layers/cudnn_conv_layer.cpp\n",
            "CXX src/caffe/layers/reshape_layer.cpp\n",
            "CXX src/caffe/layers/filter_layer.cpp\n",
            "CXX src/caffe/layers/hinge_loss_layer.cpp\n",
            "CXX src/caffe/layers/cudnn_deconv_layer.cpp\n",
            "CXX src/caffe/layers/softmax_loss_layer.cpp\n",
            "CXX src/caffe/layers/cudnn_lrn_layer.cpp\n",
            "CXX src/caffe/layers/elu_layer.cpp\n",
            "CXX src/caffe/layers/log_layer.cpp\n",
            "CXX src/caffe/layers/sigmoid_layer.cpp\n",
            "CXX src/caffe/layers/parameter_layer.cpp\n",
            "CXX src/caffe/layers/base_data_layer.cpp\n",
            "CXX src/caffe/layers/infogain_loss_layer.cpp\n",
            "CXX src/caffe/layers/recurrent_layer.cpp\n",
            "CXX src/caffe/layers/mvn_layer.cpp\n",
            "CXX src/caffe/layers/crop_layer.cpp\n",
            "CXX src/caffe/layers/argmax_layer.cpp\n",
            "CXX src/caffe/layers/multinomial_logistic_loss_layer.cpp\n",
            "CXX src/caffe/layers/window_data_layer.cpp\n",
            "CXX src/caffe/layers/pooling_layer.cpp\n",
            "CXX src/caffe/layers/bias_layer.cpp\n",
            "CXX src/caffe/layers/accuracy_layer.cpp\n",
            "CXX src/caffe/layers/cudnn_pooling_layer.cpp\n",
            "CXX src/caffe/layers/contrastive_loss_layer.cpp\n",
            "CXX src/caffe/layers/concat_layer.cpp\n",
            "CXX src/caffe/layers/silence_layer.cpp\n",
            "CXX src/caffe/layers/bnll_layer.cpp\n",
            "CXX src/caffe/layers/lrn_layer.cpp\n",
            "CXX src/caffe/layers/input_layer.cpp\n",
            "CXX src/caffe/layers/embed_layer.cpp\n",
            "CXX src/caffe/layers/hdf5_data_layer.cpp\n",
            "CXX src/caffe/layers/power_layer.cpp\n",
            "CXX src/caffe/layers/deconv_layer.cpp\n",
            "CXX src/caffe/layers/neuron_layer.cpp\n",
            "CXX src/caffe/layers/euclidean_loss_layer.cpp\n",
            "CXX src/caffe/util/upgrade_proto.cpp\n",
            "CXX src/caffe/util/hdf5.cpp\n",
            "CXX src/caffe/util/math_functions.cpp\n",
            "CXX src/caffe/util/blocking_queue.cpp\n",
            "CXX src/caffe/util/im2col.cpp\n",
            "CXX src/caffe/util/db.cpp\n",
            "CXX src/caffe/util/db_leveldb.cpp\n",
            "CXX src/caffe/util/benchmark.cpp\n",
            "CXX src/caffe/util/insert_splits.cpp\n",
            "CXX src/caffe/util/db_lmdb.cpp\n",
            "CXX src/caffe/util/cudnn.cpp\n",
            "CXX src/caffe/util/io.cpp\n",
            "CXX src/caffe/util/signal_handler.cpp\n",
            "CXX src/caffe/solvers/adagrad_solver.cpp\n",
            "CXX src/caffe/solvers/rmsprop_solver.cpp\n",
            "CXX src/caffe/solvers/sgd_solver.cpp\n",
            "CXX src/caffe/solvers/adadelta_solver.cpp\n",
            "CXX src/caffe/solvers/adam_solver.cpp\n",
            "CXX src/caffe/solvers/nesterov_solver.cpp\n",
            "CXX src/caffe/parallel.cpp\n",
            "CXX src/caffe/layer.cpp\n",
            "CXX src/caffe/blob.cpp\n",
            "CXX src/caffe/net.cpp\n",
            "CXX src/caffe/common.cpp\n",
            "AR -o .build_release/lib/libcaffe.a\n",
            "LD -o .build_release/lib/libcaffe.so.1.0.0\n",
            "CXX/LD -o .build_release/tools/upgrade_solver_proto_text.bin\n",
            "CXX/LD -o .build_release/tools/compute_image_mean.bin\n",
            "CXX/LD -o .build_release/tools/caffe.bin\n",
            "CXX/LD -o .build_release/tools/upgrade_net_proto_text.bin\n",
            "CXX/LD -o .build_release/tools/upgrade_net_proto_binary.bin\n",
            "CXX/LD -o .build_release/tools/extract_features.bin\n",
            "CXX/LD -o .build_release/tools/convert_imageset.bin\n",
            "CXX/LD -o .build_release/examples/mnist/convert_mnist_data.bin\n",
            "CXX/LD -o .build_release/examples/cifar10/convert_cifar_data.bin\n",
            "CXX/LD -o .build_release/examples/cpp_classification/classification.bin\n",
            "CXX/LD -o .build_release/examples/siamese/convert_mnist_siamese_data.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*THE FOLLOWING PART WAS ADDED TO TRY TO SOLVE \"Import \"caffe\" could not be resolved\" encountered in section Classification: Instant Recognition with Caffe (deeplab v2 example 00-classification)*"
      ],
      "metadata": {
        "id": "3zUmMHPHBnlR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!make pycaffe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bd7CH2r4idKO",
        "outputId": "ceb956ed-6354-43b3-93d1-dcd736fcf082"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CXX/LD -o python/caffe/_caffe.so python/caffe/_caffe.cpp\n",
            "touch python/caffe/proto/__init__.py\n",
            "PROTOC (python) src/caffe/proto/caffe.proto\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*THE FOLLOWING PART WAS ADDED TO TRY TO SOLVE \"Import \"caffe\" could not be resolved\" encountered in section Classification: Instant Recognition with Caffe (deeplab v2 example 00-classification)*"
      ],
      "metadata": {
        "id": "6ZGPUDUYBwVi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "if \":/content/caffe/python\" not in os.environ['PYTHONPATH']:\n",
        "  print(\"it is not in\");  \n",
        "  os.environ['PYTHONPATH'] = os.environ['PYTHONPATH']+\":/content/caffe/python\"\n",
        "else:\n",
        "  print(\"it is in\");\n",
        "print(os.environ['PYTHONPATH'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUXmGiYW7lLM",
        "outputId": "056745a1-a690-4280-dd06-a4a097e1ccee"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "it is not in\n",
            "/env/python:/content/caffe/python\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classification: Instant Recognition with Caffe (deeplab v2 example 00-classification)\n",
        "\n",
        "Now that's the Caffe lib is installed, from the [repository](https://bitbucket.org/aquariusjay/deeplab-public-ver2/src/master/) we try to proceed the content of the file [`/examples/00-classification.ipynb`](https://bitbucket.org/aquariusjay/deeplab-public-ver2/src/master/examples/00-classification.ipynb).\n",
        "\n"
      ],
      "metadata": {
        "id": "95awtV2PYlol"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set up Python environment: numpy for numerical routines, and matplotlib for plotting\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# display plots in this notebook\n",
        "%matplotlib inline\n",
        "\n",
        "# set display defaults\n",
        "plt.rcParams['figure.figsize'] = (10, 10)        # large images\n",
        "plt.rcParams['image.interpolation'] = 'nearest'  # don't interpolate: show square pixels\n",
        "plt.rcParams['image.cmap'] = 'gray'  # use grayscale output rather than a (potentially misleading) color heatmap\n"
      ],
      "metadata": {
        "id": "eEUsoShRYf-I"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `import caffe` does not throw a \"No module named _caffe\" as commented in the code taken from the deeplabv2 repository. Nevertheless as explained afterwards the caffe lib is not recognized."
      ],
      "metadata": {
        "id": "VVl_5mqHB54b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The caffe module needs to be on the Python path;\n",
        "#  we'll add it here explicitly.\n",
        "import sys\n",
        "caffe_root = '/content/caffe'  # this file should be run from {caffe_root}/examples (otherwise change this line) # I set up to the caffe lib imported previously\n",
        "sys.path.insert(0, caffe_root + 'python')\n",
        "\n",
        "import caffe\n",
        "# If you get \"No module named _caffe\", either you have not built pycaffe or you have the wrong path.\n"
      ],
      "metadata": {
        "id": "-m0O_HK8aIQX"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Caffe error\n",
        "As you can notice in code part above caffe is underlined. And there is a message `Import \"caffe\" could not be resolved(reportMissingImports)` \n",
        "\n",
        "I've tried to resolve this error following the hints found in those threads: \n",
        "- https://stackoverflow.com/questions/28177298/import-caffe-error\n",
        " - And this other thread linked to it: https://stackoverflow.com/questions/31358451/make-pycaffe-fatal-error-python-h-file-not-found\n",
        "- https://github.com/BVLC/caffe/issues/263#issuecomment-38771502\n",
        "\n",
        "\n",
        "See the code before section \"Classification: Instant Recognition with Caffe (deeplab v2 example 00-classification)\":\n",
        "- I tried: `%cd /content/caffe \\ !make pycaffe` the command works with no error but it does not change anything\n",
        "- As advised [here](https://stackoverflow.com/questions/31358451/make-pycaffe-fatal-error-python-h-file-not-found) Tryed `!find / -name 'Python.h'` and updated the `/content/caffe/Make.config` with:  \n",
        "  - `!sed -i 's/PYTHON_INCLUDE := \\/usr\\/include\\/python2.7 \\\\/# PYTHON_INCLUDE := \\/usr\\/include\\/python2.7 \\\\/' Makefile.config`\n",
        "  - `!sed -i 's/\\/usr\\/lib\\/python2.7\\/dist-packages\\/numpy\\/core\\/include/# \\/usr\\/lib\\/python2.7\\/dist-packages\\/numpy\\/core\\/include/' Makefile.config` \n",
        "  - `!sed -i 's/# PYTHON_INCLUDE := \\/usr\\/include\\/python3.5m \\\\/PYTHON_INCLUDE := \\/usr\\/include\\/python3.7m \\\\/' Makefile.config `\n",
        "  - `!sed -i 's/#                 \\/usr\\/lib\\/python3.5\\/dist-packages\\/numpy\\/core\\/include/                 \\/usr\\/local\\/lib\\/python3.7\\/dist-packages\\/numpy\\/core\\/include/' Makefile.config `\n",
        " \n",
        "before executing `%cd /content/caffe \\ !make pycaffe` \n",
        "\n"
      ],
      "metadata": {
        "id": "pZQtFznro1sV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "if os.path.isfile(caffe_root + 'models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel'):\n",
        "    print('CaffeNet found.')\n",
        "else:\n",
        "    print('Downloading pre-trained CaffeNet model...')\n",
        "    !/content/caffe/scripts/download_model_binary.py /content/caffe/models/bvlc_reference_caffenet\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgrgvOF3aheq",
        "outputId": "e14369ef-b0cf-4a70-b871-74a2f0c9f4a3"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading pre-trained CaffeNet model...\n",
            "Model already exists.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "caffe.set_mode_cpu()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "Ed35zQyNczcB",
        "outputId": "d6c2b1f2-2c37-4eb1-9391-c22ad09690f5"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-46a4bc332b49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcaffe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_mode_cpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: module 'caffe' has no attribute 'set_mode_cpu'"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "RCP209_deeplabv2-test_00_classement-failling_to_import_caffe_lib.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMFhwIotlL7GtFPeEqisOyC",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}