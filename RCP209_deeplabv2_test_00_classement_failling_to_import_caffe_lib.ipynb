{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nyluje/RCP209DeeplabExperiment/blob/main/RCP209_deeplabv2_test_00_classement_failling_to_import_caffe_lib.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experimentation of Deeplab v2 in Google Colab (with build from source Caffe lib installation)\n",
        "\n",
        "## Introduction\n",
        "\n",
        "For academic purpose, this notebook is meant to experiment Deeplab v2 as described in [Liang-Chieh Chen web page](http://liangchiehchen.com/projects/DeepLab.html) through a Notebook running in Google Colab. The page gives direction to the code located at this [repository](https://bitbucket.org/aquariusjay/deeplab-public-ver2/src/master/)."
      ],
      "metadata": {
        "id": "cmuWF-aVb3Bb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!lsb_release -a\n",
        "!python --version\n",
        "!nvcc --version\n",
        "import cv2\n",
        "print(cv2.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_giCGYVc5ZCK",
        "outputId": "02eba746-8650-4b77-ca8d-c2587ca5878b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No LSB modules are available.\n",
            "Distributor ID:\tUbuntu\n",
            "Description:\tUbuntu 18.04.5 LTS\n",
            "Release:\t18.04\n",
            "Codename:\tbionic\n",
            "Python 3.7.12\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Mon_Oct_12_20:09:46_PDT_2020\n",
            "Cuda compilation tools, release 11.1, V11.1.105\n",
            "Build cuda_11.1.TC455_06.29190527_0\n",
            "4.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IR2O9TlPTIpI",
        "outputId": "e18410b2-2b5a-4822-cf3a-12dd0b51764f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'deeplabv2'...\n",
            "Receiving objects: 100% (765/765), 7.11 MiB | 12.33 MiB/s, done.\n",
            "Resolving deltas: 100% (173/173), done.\n"
          ]
        }
      ],
      "source": [
        "!mkdir deeplabv2\n",
        "!git clone https://bitbucket.org/aquariusjay/deeplab-public-ver2/src/master/ deeplabv2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Caffe lib installation\n",
        "\n",
        "The Caffe lib needs to be installed in Google Colab in order to use the example code from Deeplab v2. \n",
        "\n",
        "Caffe lib installation in Google Colab reproduces the steps explained in this [Medium article](https://filip-drapejkowski.medium.com/caffe-in-google-colab-2021-2d730989c849) and [its Google Colab implementation example](https://colab.research.google.com/github/Huxwell/caffe-colab/blob/main/caffe_details.ipynb#scrollTo=iDt9JEiq5qHd) (comments have been added ahead of code chunks duplicated from this work).\n",
        "\n"
      ],
      "metadata": {
        "id": "cK2KtYXNbbIc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HheSRB1T8OA",
        "outputId": "c4b92788-cbca-4e42-eeb9-f29d930dddde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'caffe'...\n",
            "remote: Enumerating objects: 65274, done.\u001b[K\n",
            "remote: Total 65274 (delta 0), reused 0 (delta 0), pack-reused 65274\u001b[K\n",
            "Receiving objects: 100% (65274/65274), 74.14 MiB | 26.36 MiB/s, done.\n",
            "Resolving deltas: 100% (41245/41245), done.\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  libgflags2.2\n",
            "0 upgraded, 1 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 72.4 kB of archives.\n",
            "After this operation, 312 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libgflags2.2 amd64 2.2.1-1 [72.4 kB]\n",
            "Fetched 72.4 kB in 0s (181 kB/s)\n",
            "Selecting previously unselected package libgflags2.2.\n",
            "(Reading database ... 155335 files and directories currently installed.)\n",
            "Preparing to unpack .../libgflags2.2_2.2.1-1_amd64.deb ...\n",
            "Unpacking libgflags2.2 (2.2.1-1) ...\n",
            "Setting up libgflags2.2 (2.2.1-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  libgflags-dev\n",
            "0 upgraded, 1 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 86.1 kB of archives.\n",
            "After this operation, 598 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libgflags-dev amd64 2.2.1-1 [86.1 kB]\n",
            "Fetched 86.1 kB in 0s (644 kB/s)\n",
            "Selecting previously unselected package libgflags-dev.\n",
            "(Reading database ... 155342 files and directories currently installed.)\n",
            "Preparing to unpack .../libgflags-dev_2.2.1-1_amd64.deb ...\n",
            "Unpacking libgflags-dev (2.2.1-1) ...\n",
            "Setting up libgflags-dev (2.2.1-1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libgoogle-glog0v5\n",
            "The following NEW packages will be installed:\n",
            "  libgoogle-glog-dev libgoogle-glog0v5\n",
            "0 upgraded, 2 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 124 kB of archives.\n",
            "After this operation, 508 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libgoogle-glog0v5 amd64 0.3.5-1 [50.5 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libgoogle-glog-dev amd64 0.3.5-1 [73.8 kB]\n",
            "Fetched 124 kB in 1s (98.6 kB/s)\n",
            "Selecting previously unselected package libgoogle-glog0v5.\n",
            "(Reading database ... 155360 files and directories currently installed.)\n",
            "Preparing to unpack .../libgoogle-glog0v5_0.3.5-1_amd64.deb ...\n",
            "Unpacking libgoogle-glog0v5 (0.3.5-1) ...\n",
            "Selecting previously unselected package libgoogle-glog-dev.\n",
            "Preparing to unpack .../libgoogle-glog-dev_0.3.5-1_amd64.deb ...\n",
            "Unpacking libgoogle-glog-dev (0.3.5-1) ...\n",
            "Setting up libgoogle-glog0v5 (0.3.5-1) ...\n",
            "Setting up libgoogle-glog-dev (0.3.5-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libhdf5-100 is already the newest version (1.10.0-patch1+docs-4).\n",
            "libhdf5-100 set to manually installed.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  libhdf5-serial-dev\n",
            "0 upgraded, 1 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 2,898 B of archives.\n",
            "After this operation, 37.9 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libhdf5-serial-dev all 1.10.0-patch1+docs-4 [2,898 B]\n",
            "Fetched 2,898 B in 0s (46.3 kB/s)\n",
            "Selecting previously unselected package libhdf5-serial-dev.\n",
            "(Reading database ... 155378 files and directories currently installed.)\n",
            "Preparing to unpack .../libhdf5-serial-dev_1.10.0-patch1+docs-4_all.deb ...\n",
            "Unpacking libhdf5-serial-dev (1.10.0-patch1+docs-4) ...\n",
            "Setting up libhdf5-serial-dev (1.10.0-patch1+docs-4) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libhdf5-dev is already the newest version (1.10.0-patch1+docs-4).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libhdf5-cpp-100 is already the newest version (1.10.0-patch1+docs-4).\n",
            "libhdf5-cpp-100 set to manually installed.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "protobuf-compiler is already the newest version (3.0.0-9.1ubuntu1).\n",
            "The following NEW packages will be installed:\n",
            "  libprotobuf-dev libprotobuf-lite10\n",
            "0 upgraded, 2 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 1,056 kB of archives.\n",
            "After this operation, 8,482 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libprotobuf-lite10 amd64 3.0.0-9.1ubuntu1 [97.7 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 libprotobuf-dev amd64 3.0.0-9.1ubuntu1 [959 kB]\n",
            "Fetched 1,056 kB in 0s (3,589 kB/s)\n",
            "Selecting previously unselected package libprotobuf-lite10:amd64.\n",
            "(Reading database ... 155382 files and directories currently installed.)\n",
            "Preparing to unpack .../libprotobuf-lite10_3.0.0-9.1ubuntu1_amd64.deb ...\n",
            "Unpacking libprotobuf-lite10:amd64 (3.0.0-9.1ubuntu1) ...\n",
            "Selecting previously unselected package libprotobuf-dev:amd64.\n",
            "Preparing to unpack .../libprotobuf-dev_3.0.0-9.1ubuntu1_amd64.deb ...\n",
            "Unpacking libprotobuf-dev:amd64 (3.0.0-9.1ubuntu1) ...\n",
            "Setting up libprotobuf-lite10:amd64 (3.0.0-9.1ubuntu1) ...\n",
            "Setting up libprotobuf-dev:amd64 (3.0.0-9.1ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# code duplicated from https://colab.research.google.com/github/Huxwell/caffe-colab/blob/main/caffe_details.ipynb#scrollTo=iDt9JEiq5qHd\n",
        "\n",
        "\n",
        "TARGET_DIR=\"/content\"\n",
        "!cd $TARGET_DIR\n",
        "!git clone https://github.com/BVLC/caffe.git\n",
        "!git reset --hard 9b891540183ddc834a02b2bd81b31afae71b2153 \n",
        "!apt-get install libgflags2.2 \n",
        "!apt-get install libgflags-dev\n",
        "!apt-get install libgoogle-glog-dev\n",
        "!apt-get install libhdf5-100\n",
        "!apt-get install libhdf5-serial-dev\n",
        "!apt-get install libhdf5-dev\n",
        "!apt-get install libhdf5-cpp-100\n",
        "!apt-get install libprotobuf-dev protobuf-compiler\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# code duplicated from https://colab.research.google.com/github/Huxwell/caffe-colab/blob/main/caffe_details.ipynb#scrollTo=iDt9JEiq5qHd\n",
        "\n",
        "!find /usr -iname \"*hdf5.so\"\n",
        "# got: /usr/lib/x86_64-linux-gnu/hdf5/serial\n",
        "!find /usr -iname \"*hdf5_hl.so\"\n",
        "!ln -s /usr/lib/x86_64-linux-gnu/libhdf5_serial.so /usr/lib/x86_64-linux-gnu/libhdf5.so\n",
        "!ln -s /usr/lib/x86_64-linux-gnu/libhdf5_serial_hl.so /usr/lib/x86_64-linux-gnu/libhdf5_hl.so\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMJWeEVBPDsL",
        "outputId": "ae766338-9ba0-40f8-9d4f-12ee6598f873"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/lib/x86_64-linux-gnu/hdf5/serial/libhdf5.so\n",
            "/usr/lib/x86_64-linux-gnu/hdf5/serial/libhdf5_hl.so\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# code duplicated from https://colab.research.google.com/github/Huxwell/caffe-colab/blob/main/caffe_details.ipynb#scrollTo=iDt9JEiq5qHd\n",
        "\n",
        "#!find /usr -iname \"*hdf5.h*\" # got:\n",
        "# /usr/include/hdf5/serial/hdf5.h \n",
        "# /usr/include/opencv2/flann/hdf5.h\n",
        "# Let's try the first one.\n",
        "%env CPATH=/usr/include/hdf5/serial/\n",
        "#fatal error: hdf5.h: No such file or directory\n",
        "\n",
        "!apt-get install libleveldb-dev\n",
        "!apt-get install libgflags-dev libgoogle-glog-dev liblmdb-dev\n",
        "!apt-get install libsnappy-dev\n",
        "\n",
        "!echo $CPATH\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_ekoSd0PFem",
        "outputId": "3bf05e30-1496-446a-8e01-66700c214dbd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: CPATH=/usr/include/hdf5/serial/\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libleveldb1v5\n",
            "Suggested packages:\n",
            "  leveldb-doc\n",
            "The following NEW packages will be installed:\n",
            "  libleveldb-dev libleveldb1v5\n",
            "0 upgraded, 2 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 313 kB of archives.\n",
            "After this operation, 1,336 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libleveldb1v5 amd64 1.20-2 [136 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 libleveldb-dev amd64 1.20-2 [177 kB]\n",
            "Fetched 313 kB in 0s (1,350 kB/s)\n",
            "Selecting previously unselected package libleveldb1v5:amd64.\n",
            "(Reading database ... 155503 files and directories currently installed.)\n",
            "Preparing to unpack .../libleveldb1v5_1.20-2_amd64.deb ...\n",
            "Unpacking libleveldb1v5:amd64 (1.20-2) ...\n",
            "Selecting previously unselected package libleveldb-dev:amd64.\n",
            "Preparing to unpack .../libleveldb-dev_1.20-2_amd64.deb ...\n",
            "Unpacking libleveldb-dev:amd64 (1.20-2) ...\n",
            "Setting up libleveldb1v5:amd64 (1.20-2) ...\n",
            "Setting up libleveldb-dev:amd64 (1.20-2) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libgflags-dev is already the newest version (2.2.1-1).\n",
            "libgoogle-glog-dev is already the newest version (0.3.5-1).\n",
            "The following NEW packages will be installed:\n",
            "  liblmdb-dev liblmdb0 lmdb-doc\n",
            "0 upgraded, 3 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 380 kB of archives.\n",
            "After this operation, 2,707 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 liblmdb0 amd64 0.9.21-1ubuntu0.1 [44.6 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 liblmdb-dev amd64 0.9.21-1ubuntu0.1 [59.6 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 lmdb-doc all 0.9.21-1ubuntu0.1 [276 kB]\n",
            "Fetched 380 kB in 1s (524 kB/s)\n",
            "Selecting previously unselected package liblmdb0:amd64.\n",
            "(Reading database ... 155531 files and directories currently installed.)\n",
            "Preparing to unpack .../liblmdb0_0.9.21-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking liblmdb0:amd64 (0.9.21-1ubuntu0.1) ...\n",
            "Selecting previously unselected package liblmdb-dev:amd64.\n",
            "Preparing to unpack .../liblmdb-dev_0.9.21-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking liblmdb-dev:amd64 (0.9.21-1ubuntu0.1) ...\n",
            "Selecting previously unselected package lmdb-doc.\n",
            "Preparing to unpack .../lmdb-doc_0.9.21-1ubuntu0.1_all.deb ...\n",
            "Unpacking lmdb-doc (0.9.21-1ubuntu0.1) ...\n",
            "Setting up liblmdb0:amd64 (0.9.21-1ubuntu0.1) ...\n",
            "Setting up liblmdb-dev:amd64 (0.9.21-1ubuntu0.1) ...\n",
            "Setting up lmdb-doc (0.9.21-1ubuntu0.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  libsnappy-dev\n",
            "0 upgraded, 1 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 27.2 kB of archives.\n",
            "After this operation, 108 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsnappy-dev amd64 1.1.7-1 [27.2 kB]\n",
            "Fetched 27.2 kB in 0s (75.0 kB/s)\n",
            "Selecting previously unselected package libsnappy-dev:amd64.\n",
            "(Reading database ... 155766 files and directories currently installed.)\n",
            "Preparing to unpack .../libsnappy-dev_1.1.7-1_amd64.deb ...\n",
            "Unpacking libsnappy-dev:amd64 (1.1.7-1) ...\n",
            "Setting up libsnappy-dev:amd64 (1.1.7-1) ...\n",
            "/usr/include/hdf5/serial/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# code duplicated from https://colab.research.google.com/github/Huxwell/caffe-colab/blob/main/caffe_details.ipynb#scrollTo=iDt9JEiq5qHd\n",
        "\n",
        "%cd /content/caffe\n",
        "!ls\n",
        "!cp Makefile.config.example Makefile.config\n",
        "!make clean\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEEN2aTcRALV",
        "outputId": "1e055ec2-d54e-48b5-8061-651faafb8568"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/caffe\n",
            "caffe.cloc\t data\t   INSTALL.md\t\t    models     tools\n",
            "cmake\t\t docker    LICENSE\t\t    python\n",
            "CMakeLists.txt\t docs\t   Makefile\t\t    README.md\n",
            "CONTRIBUTING.md  examples  Makefile.config.example  scripts\n",
            "CONTRIBUTORS.md  include   matlab\t\t    src\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*THE FOLLOWING PART WAS ADDED TO TRY TO SOLVE \"Import \"caffe\" could not be resolved\" encountered in section Classification: Instant Recognition with Caffe (deeplab v2 example 00-classification)*"
      ],
      "metadata": {
        "id": "uJmCNP7GBCPw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!sed -i 's/PYTHON_INCLUDE := \\/usr\\/include\\/python2.7 \\\\/# PYTHON_INCLUDE := \\/usr\\/include\\/python2.7 \\\\/' Makefile.config \n",
        "!sed -i 's/\\/usr\\/lib\\/python2.7\\/dist-packages\\/numpy\\/core\\/include/# \\/usr\\/lib\\/python2.7\\/dist-packages\\/numpy\\/core\\/include/' Makefile.config \n",
        "!sed -i 's/# PYTHON_INCLUDE := \\/usr\\/include\\/python3.5m \\\\/PYTHON_INCLUDE := \\/usr\\/include\\/python3.7m \\\\/' Makefile.config \n",
        "!sed -i 's/#                 \\/usr\\/lib\\/python3.5\\/dist-packages\\/numpy\\/core\\/include/                 \\/usr\\/local\\/lib\\/python3.7\\/dist-packages\\/numpy\\/core\\/include/' Makefile.config \n",
        "\n",
        "!sed -i 's/# WITH_PYTHON_LAYER := 1/WITH_PYTHON_LAYER := 1/' Makefile.config \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Tg_e9M-q2yqt"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# code duplicated from https://colab.research.google.com/github/Huxwell/caffe-colab/blob/main/caffe_details.ipynb#scrollTo=iDt9JEiq5qHd\n",
        "\n",
        "!sed -i 's/-gencode arch=compute_20/#-gencode arch=compute_20/' Makefile.config #old cuda versions won't compile \n",
        "!sed -i 's/\\/usr\\/local\\/include/\\/usr\\/local\\/include \\/usr\\/include\\/hdf5\\/serial\\//'  Makefile.config #one of the 4 things needed to fix hdf5 issues\n",
        "!sed -i 's/# OPENCV_VERSION := 3/OPENCV_VERSION := 3/' Makefile.config #We actually use opencv 4.1.2, but it's similar enough to opencv 3.\n",
        "!sed -i 's/code=compute_61/code=compute_61 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_75,code=compute_75/' Makefile.config #support for new GPUs\n",
        "\n",
        "!make all -j 4 "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVIqjSdXR2_i",
        "outputId": "200e011d-7119-41e3-e062-6c8a91bc5a16"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PROTOC src/caffe/proto/caffe.proto\n",
            "NVCC src/caffe/layers/cudnn_relu_layer.cu\n",
            "NVCC src/caffe/layers/lrn_layer.cu\n",
            "NVCC src/caffe/layers/batch_norm_layer.cu\n",
            "NVCC src/caffe/layers/cudnn_conv_layer.cu\n",
            "NVCC src/caffe/layers/split_layer.cu\n",
            "NVCC src/caffe/layers/accuracy_layer.cu\n",
            "NVCC src/caffe/layers/deconv_layer.cu\n",
            "NVCC src/caffe/layers/cudnn_lcn_layer.cu\n",
            "NVCC src/caffe/layers/recurrent_layer.cu\n",
            "NVCC src/caffe/layers/hdf5_output_layer.cu\n",
            "NVCC src/caffe/layers/exp_layer.cu\n",
            "NVCC src/caffe/layers/sigmoid_cross_entropy_loss_layer.cu\n",
            "NVCC src/caffe/layers/bias_layer.cu\n",
            "NVCC src/caffe/layers/cudnn_softmax_layer.cu\n",
            "NVCC src/caffe/layers/embed_layer.cu\n",
            "NVCC src/caffe/layers/power_layer.cu\n",
            "NVCC src/caffe/layers/euclidean_loss_layer.cu\n",
            "NVCC src/caffe/layers/dropout_layer.cu\n",
            "NVCC src/caffe/layers/contrastive_loss_layer.cu\n",
            "NVCC src/caffe/layers/swish_layer.cu\n",
            "NVCC src/caffe/layers/softmax_loss_layer.cu\n",
            "NVCC src/caffe/layers/pooling_layer.cu\n",
            "NVCC src/caffe/layers/crop_layer.cu\n",
            "NVCC src/caffe/layers/im2col_layer.cu\n",
            "NVCC src/caffe/layers/threshold_layer.cu\n",
            "NVCC src/caffe/layers/scale_layer.cu\n",
            "NVCC src/caffe/layers/concat_layer.cu\n",
            "NVCC src/caffe/layers/log_layer.cu\n",
            "NVCC src/caffe/layers/lstm_unit_layer.cu\n",
            "NVCC src/caffe/layers/absval_layer.cu\n",
            "NVCC src/caffe/layers/sigmoid_layer.cu\n",
            "NVCC src/caffe/layers/slice_layer.cu\n",
            "NVCC src/caffe/layers/conv_layer.cu\n",
            "NVCC src/caffe/layers/filter_layer.cu\n",
            "NVCC src/caffe/layers/cudnn_pooling_layer.cu\n",
            "NVCC src/caffe/layers/base_data_layer.cu\n",
            "NVCC src/caffe/layers/hdf5_data_layer.cu\n",
            "NVCC src/caffe/layers/inner_product_layer.cu\n",
            "NVCC src/caffe/layers/elu_layer.cu\n",
            "NVCC src/caffe/layers/softmax_layer.cu\n",
            "NVCC src/caffe/layers/relu_layer.cu\n",
            "NVCC src/caffe/layers/cudnn_deconv_layer.cu\n",
            "NVCC src/caffe/layers/clip_layer.cu\n",
            "NVCC src/caffe/layers/cudnn_sigmoid_layer.cu\n",
            "NVCC src/caffe/layers/mvn_layer.cu\n",
            "NVCC src/caffe/layers/bnll_layer.cu\n",
            "NVCC src/caffe/layers/cudnn_lrn_layer.cu\n",
            "NVCC src/caffe/layers/silence_layer.cu\n",
            "NVCC src/caffe/layers/cudnn_tanh_layer.cu\n",
            "NVCC src/caffe/layers/tanh_layer.cu\n",
            "NVCC src/caffe/layers/prelu_layer.cu\n",
            "NVCC src/caffe/layers/reduction_layer.cu\n",
            "NVCC src/caffe/layers/eltwise_layer.cu\n",
            "NVCC src/caffe/layers/tile_layer.cu\n",
            "NVCC src/caffe/layers/batch_reindex_layer.cu\n",
            "NVCC src/caffe/util/math_functions.cu\n",
            "In file included from \u001b[01m\u001b[Ksrc/caffe/util/math_functions.cu:1:0\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/cuda/include/math_functions.h:54:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"math_functions.h is an internal header file and must not be used directly.  This file will be removed in a future CUDA release.  Please use cuda_runtime_api.h or cuda_runtime.h instead.\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\n",
            " #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"math_functions.h is an internal header file and must not be used directly.  This file will be removed in a future CUDA release.  Please use cuda_runtime_api.h or cuda_runtime.h instead.\"\n",
            "  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[Ksrc/caffe/util/math_functions.cu:1:0\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/cuda/include/math_functions.h:54:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"math_functions.h is an internal header file and must not be used directly.  This file will be removed in a future CUDA release.  Please use cuda_runtime_api.h or cuda_runtime.h instead.\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\n",
            " #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"math_functions.h is an internal header file and must not be used directly.  This file will be removed in a future CUDA release.  Please use cuda_runtime_api.h or cuda_runtime.h instead.\"\n",
            "  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "NVCC src/caffe/util/im2col.cu\n",
            "NVCC src/caffe/solvers/sgd_solver.cu\n",
            "NVCC src/caffe/solvers/adagrad_solver.cu\n",
            "In file included from src/caffe/util/math_functions.cu:1:0:\n",
            "/usr/local/cuda/include/math_functions.h:54:2: warning: #warning \"math_functions.h is an internal header file and must not be used directly.  This file will be removed in a future CUDA release.  Please use cuda_runtime_api.h or cuda_runtime.h instead.\" [-Wcpp]\n",
            " #warning \"math_functions.h is an internal header file and must not be used directly.  This file will be removed in a future CUDA release.  Please use cuda_runtime_api.h or cuda_runtime.h instead.\"\n",
            "  ^~~~~~~\n",
            "In file included from src/caffe/util/math_functions.cu:1:0:\n",
            "/usr/local/cuda/include/math_functions.h:54:2: warning: #warning \"math_functions.h is an internal header file and must not be used directly.  This file will be removed in a future CUDA release.  Please use cuda_runtime_api.h or cuda_runtime.h instead.\" [-Wcpp]\n",
            " #warning \"math_functions.h is an internal header file and must not be used directly.  This file will be removed in a future CUDA release.  Please use cuda_runtime_api.h or cuda_runtime.h instead.\"\n",
            "  ^~~~~~~\n",
            "NVCC src/caffe/solvers/adam_solver.cu\n",
            "NVCC src/caffe/solvers/nesterov_solver.cu\n",
            "NVCC src/caffe/solvers/rmsprop_solver.cu\n",
            "NVCC src/caffe/solvers/adadelta_solver.cu\n",
            "CXX tools/upgrade_net_proto_text.cpp\n",
            "CXX tools/upgrade_solver_proto_text.cpp\n",
            "CXX tools/caffe.cpp\n",
            "CXX tools/compute_image_mean.cpp\n",
            "CXX tools/extract_features.cpp\n",
            "CXX tools/upgrade_net_proto_binary.cpp\n",
            "CXX tools/convert_imageset.cpp\n",
            "CXX examples/mnist/convert_mnist_data.cpp\n",
            "CXX examples/cifar10/convert_cifar_data.cpp\n",
            "CXX examples/cpp_classification/classification.cpp\n",
            "CXX examples/siamese/convert_mnist_siamese_data.cpp\n",
            "CXX .build_release/src/caffe/proto/caffe.pb.cc\n",
            "CXX src/caffe/layer_factory.cpp\n",
            "CXX src/caffe/internal_thread.cpp\n",
            "CXX src/caffe/data_transformer.cpp\n",
            "CXX src/caffe/solver.cpp\n",
            "CXX src/caffe/syncedmem.cpp\n",
            "CXX src/caffe/layers/prelu_layer.cpp\n",
            "CXX src/caffe/layers/scale_layer.cpp\n",
            "CXX src/caffe/layers/slice_layer.cpp\n",
            "CXX src/caffe/layers/batch_reindex_layer.cpp\n",
            "CXX src/caffe/layers/loss_layer.cpp\n",
            "CXX src/caffe/layers/image_data_layer.cpp\n",
            "CXX src/caffe/layers/cudnn_tanh_layer.cpp\n",
            "CXX src/caffe/layers/rnn_layer.cpp\n",
            "CXX src/caffe/layers/sigmoid_cross_entropy_loss_layer.cpp\n",
            "CXX src/caffe/layers/threshold_layer.cpp\n",
            "CXX src/caffe/layers/absval_layer.cpp\n",
            "CXX src/caffe/layers/tanh_layer.cpp\n",
            "CXX src/caffe/layers/cudnn_lcn_layer.cpp\n",
            "CXX src/caffe/layers/tile_layer.cpp\n",
            "CXX src/caffe/layers/cudnn_softmax_layer.cpp\n",
            "CXX src/caffe/layers/split_layer.cpp\n",
            "CXX src/caffe/layers/lstm_unit_layer.cpp\n",
            "CXX src/caffe/layers/flatten_layer.cpp\n",
            "CXX src/caffe/layers/swish_layer.cpp\n",
            "CXX src/caffe/layers/dropout_layer.cpp\n",
            "CXX src/caffe/layers/lstm_layer.cpp\n",
            "CXX src/caffe/layers/conv_layer.cpp\n",
            "CXX src/caffe/layers/inner_product_layer.cpp\n",
            "CXX src/caffe/layers/clip_layer.cpp\n",
            "CXX src/caffe/layers/batch_norm_layer.cpp\n",
            "CXX src/caffe/layers/hdf5_output_layer.cpp\n",
            "CXX src/caffe/layers/base_conv_layer.cpp\n",
            "CXX src/caffe/layers/data_layer.cpp\n",
            "CXX src/caffe/layers/exp_layer.cpp\n",
            "CXX src/caffe/layers/eltwise_layer.cpp\n",
            "CXX src/caffe/layers/reduction_layer.cpp\n",
            "CXX src/caffe/layers/relu_layer.cpp\n",
            "CXX src/caffe/layers/dummy_data_layer.cpp\n",
            "CXX src/caffe/layers/softmax_layer.cpp\n",
            "CXX src/caffe/layers/cudnn_sigmoid_layer.cpp\n",
            "CXX src/caffe/layers/im2col_layer.cpp\n",
            "CXX src/caffe/layers/memory_data_layer.cpp\n",
            "CXX src/caffe/layers/spp_layer.cpp\n",
            "CXX src/caffe/layers/cudnn_relu_layer.cpp\n",
            "CXX src/caffe/layers/cudnn_conv_layer.cpp\n",
            "CXX src/caffe/layers/reshape_layer.cpp\n",
            "CXX src/caffe/layers/filter_layer.cpp\n",
            "CXX src/caffe/layers/hinge_loss_layer.cpp\n",
            "CXX src/caffe/layers/cudnn_deconv_layer.cpp\n",
            "CXX src/caffe/layers/softmax_loss_layer.cpp\n",
            "CXX src/caffe/layers/cudnn_lrn_layer.cpp\n",
            "CXX src/caffe/layers/elu_layer.cpp\n",
            "CXX src/caffe/layers/log_layer.cpp\n",
            "CXX src/caffe/layers/sigmoid_layer.cpp\n",
            "CXX src/caffe/layers/parameter_layer.cpp\n",
            "CXX src/caffe/layers/base_data_layer.cpp\n",
            "CXX src/caffe/layers/infogain_loss_layer.cpp\n",
            "CXX src/caffe/layers/recurrent_layer.cpp\n",
            "CXX src/caffe/layers/mvn_layer.cpp\n",
            "CXX src/caffe/layers/crop_layer.cpp\n",
            "CXX src/caffe/layers/argmax_layer.cpp\n",
            "CXX src/caffe/layers/multinomial_logistic_loss_layer.cpp\n",
            "CXX src/caffe/layers/window_data_layer.cpp\n",
            "CXX src/caffe/layers/pooling_layer.cpp\n",
            "CXX src/caffe/layers/bias_layer.cpp\n",
            "CXX src/caffe/layers/accuracy_layer.cpp\n",
            "CXX src/caffe/layers/cudnn_pooling_layer.cpp\n",
            "CXX src/caffe/layers/contrastive_loss_layer.cpp\n",
            "CXX src/caffe/layers/concat_layer.cpp\n",
            "CXX src/caffe/layers/silence_layer.cpp\n",
            "CXX src/caffe/layers/bnll_layer.cpp\n",
            "CXX src/caffe/layers/lrn_layer.cpp\n",
            "CXX src/caffe/layers/input_layer.cpp\n",
            "CXX src/caffe/layers/embed_layer.cpp\n",
            "CXX src/caffe/layers/hdf5_data_layer.cpp\n",
            "CXX src/caffe/layers/power_layer.cpp\n",
            "CXX src/caffe/layers/deconv_layer.cpp\n",
            "CXX src/caffe/layers/neuron_layer.cpp\n",
            "CXX src/caffe/layers/euclidean_loss_layer.cpp\n",
            "CXX src/caffe/util/upgrade_proto.cpp\n",
            "CXX src/caffe/util/hdf5.cpp\n",
            "CXX src/caffe/util/math_functions.cpp\n",
            "CXX src/caffe/util/blocking_queue.cpp\n",
            "CXX src/caffe/util/im2col.cpp\n",
            "CXX src/caffe/util/db.cpp\n",
            "CXX src/caffe/util/db_leveldb.cpp\n",
            "CXX src/caffe/util/benchmark.cpp\n",
            "CXX src/caffe/util/insert_splits.cpp\n",
            "CXX src/caffe/util/db_lmdb.cpp\n",
            "CXX src/caffe/util/cudnn.cpp\n",
            "CXX src/caffe/util/io.cpp\n",
            "CXX src/caffe/util/signal_handler.cpp\n",
            "CXX src/caffe/solvers/adagrad_solver.cpp\n",
            "CXX src/caffe/solvers/rmsprop_solver.cpp\n",
            "CXX src/caffe/solvers/sgd_solver.cpp\n",
            "CXX src/caffe/solvers/adadelta_solver.cpp\n",
            "CXX src/caffe/solvers/adam_solver.cpp\n",
            "CXX src/caffe/solvers/nesterov_solver.cpp\n",
            "CXX src/caffe/parallel.cpp\n",
            "CXX src/caffe/layer.cpp\n",
            "CXX src/caffe/blob.cpp\n",
            "CXX src/caffe/net.cpp\n",
            "CXX src/caffe/common.cpp\n",
            "AR -o .build_release/lib/libcaffe.a\n",
            "LD -o .build_release/lib/libcaffe.so.1.0.0\n",
            "CXX/LD -o .build_release/tools/upgrade_solver_proto_text.bin\n",
            "CXX/LD -o .build_release/tools/upgrade_net_proto_text.bin\n",
            "CXX/LD -o .build_release/tools/caffe.bin\n",
            "CXX/LD -o .build_release/tools/compute_image_mean.bin\n",
            "CXX/LD -o .build_release/tools/extract_features.bin\n",
            "CXX/LD -o .build_release/tools/upgrade_net_proto_binary.bin\n",
            "CXX/LD -o .build_release/tools/convert_imageset.bin\n",
            "CXX/LD -o .build_release/examples/mnist/convert_mnist_data.bin\n",
            "CXX/LD -o .build_release/examples/cifar10/convert_cifar_data.bin\n",
            "CXX/LD -o .build_release/examples/cpp_classification/classification.bin\n",
            "CXX/LD -o .build_release/examples/siamese/convert_mnist_siamese_data.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*THE FOLLOWING PART WAS ADDED TO TRY TO SOLVE \"Import \"caffe\" could not be resolved\" encountered in section Classification: Instant Recognition with Caffe (deeplab v2 example 00-classification)*"
      ],
      "metadata": {
        "id": "3zUmMHPHBnlR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!make pycaffe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bd7CH2r4idKO",
        "outputId": "784b2167-1ddd-46b3-d077-ea5f4b6bf372"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CXX/LD -o python/caffe/_caffe.so python/caffe/_caffe.cpp\n",
            "touch python/caffe/proto/__init__.py\n",
            "PROTOC (python) src/caffe/proto/caffe.proto\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*THE FOLLOWING PART WAS ADDED TO TRY TO SOLVE \"Import \"caffe\" could not be resolved\" encountered in section Classification: Instant Recognition with Caffe (deeplab v2 example 00-classification)*"
      ],
      "metadata": {
        "id": "6ZGPUDUYBwVi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "if \":/content/caffe/python\" not in os.environ['PYTHONPATH']:\n",
        "  print(\"it is not in\");  \n",
        "  os.environ['PYTHONPATH'] = os.environ['PYTHONPATH']+\":/content/caffe/python\"\n",
        "else:\n",
        "  print(\"it is in\");\n",
        "print(os.environ['PYTHONPATH'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUXmGiYW7lLM",
        "outputId": "e4e50391-5c72-4b6e-8aac-5f4ff8253610"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "it is not in\n",
            "/env/python:/content/caffe/python\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classification: Instant Recognition with Caffe (deeplab v2 example 00-classification)\n",
        "\n",
        "Now that's the Caffe lib is installed, from the [Deeplab v2 repository](https://bitbucket.org/aquariusjay/deeplab-public-ver2/src/master/), the content of the file [`/examples/00-classification.ipynb`](https://bitbucket.org/aquariusjay/deeplab-public-ver2/src/master/examples/00-classification.ipynb) is replicated step by step in order to experiment.\n",
        "\n"
      ],
      "metadata": {
        "id": "95awtV2PYlol"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set up Python environment: numpy for numerical routines, and matplotlib for plotting\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# display plots in this notebook\n",
        "%matplotlib inline\n",
        "\n",
        "# set display defaults\n",
        "plt.rcParams['figure.figsize'] = (10, 10)        # large images\n",
        "plt.rcParams['image.interpolation'] = 'nearest'  # don't interpolate: show square pixels\n",
        "plt.rcParams['image.cmap'] = 'gray'  # use grayscale output rather than a (potentially misleading) color heatmap\n"
      ],
      "metadata": {
        "id": "eEUsoShRYf-I"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `import caffe` does not throw a \"No module named _caffe\" as commented in the code taken from the deeplabv2 repository. Nevertheless as explained afterwards the caffe lib is not recognized."
      ],
      "metadata": {
        "id": "VVl_5mqHB54b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The caffe module needs to be on the Python path;\n",
        "#  we'll add it here explicitly.\n",
        "import sys\n",
        "caffe_root = '/content/caffe/'  # this file should be run from {caffe_root}/examples (otherwise change this line) # I set up to the caffe lib imported previously\n",
        "sys.path.insert(0, caffe_root + 'python')\n",
        "\n",
        "import caffe\n",
        "# If you get \"No module named _caffe\", either you have not built pycaffe or you have the wrong path.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "-m0O_HK8aIQX",
        "outputId": "51563a57-a1a0-44cb-ce27-ea71b5463032"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-aab5c9687e70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaffe_root\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcaffe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m# If you get \"No module named _caffe\", either you have not built pycaffe or you have the wrong path.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/caffe/python/caffe/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpycaffe\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSGDSolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNesterovSolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAdaGradSolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRMSPropSolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAdaDeltaSolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAdamSolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNCCL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTimer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_caffe\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minit_log\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_mode_cpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_mode_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_solver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_type_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_random_seed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_solver_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_rank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_solver_rank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_multiprocess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_nccl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_caffe\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaffe_pb2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTEST\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/caffe/python/caffe/pycaffe.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_caffe\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSGDSolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNesterovSolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAdaGradSolver\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mRMSPropSolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAdaDeltaSolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAdamSolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNCCL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTimer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcaffe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: /content/caffe/python/caffe/_caffe.so: undefined symbol: _ZN5boost6python6detail11init_moduleER11PyModuleDefPFvvE",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Caffe error\n",
        "As you can notice in code part above caffe is underlined. And there is a message `Import \"caffe\" could not be resolved(reportMissingImports)` \n",
        "\n",
        "I've tried to resolve this error following the hints found in those threads: \n",
        "- https://stackoverflow.com/questions/28177298/import-caffe-error\n",
        " - And this other thread linked to it: https://stackoverflow.com/questions/31358451/make-pycaffe-fatal-error-python-h-file-not-found\n",
        "- https://github.com/BVLC/caffe/issues/263#issuecomment-38771502\n",
        "\n",
        "\n",
        "See the code before section \"Classification: Instant Recognition with Caffe (deeplab v2 example 00-classification)\":\n",
        "- I tried: `%cd /content/caffe \\ !make pycaffe` the command works with no error but it does not change anything\n",
        "- As advised [here](https://stackoverflow.com/questions/31358451/make-pycaffe-fatal-error-python-h-file-not-found) Tryed `!find / -name 'Python.h'` and updated the `/content/caffe/Make.config` with:  \n",
        "  - `!sed -i 's/PYTHON_INCLUDE := \\/usr\\/include\\/python2.7 \\\\/# PYTHON_INCLUDE := \\/usr\\/include\\/python2.7 \\\\/' Makefile.config`\n",
        "  - `!sed -i 's/\\/usr\\/lib\\/python2.7\\/dist-packages\\/numpy\\/core\\/include/# \\/usr\\/lib\\/python2.7\\/dist-packages\\/numpy\\/core\\/include/' Makefile.config` \n",
        "  - `!sed -i 's/# PYTHON_INCLUDE := \\/usr\\/include\\/python3.5m \\\\/PYTHON_INCLUDE := \\/usr\\/include\\/python3.7m \\\\/' Makefile.config `\n",
        "  - `!sed -i 's/#                 \\/usr\\/lib\\/python3.5\\/dist-packages\\/numpy\\/core\\/include/                 \\/usr\\/local\\/lib\\/python3.7\\/dist-packages\\/numpy\\/core\\/include/' Makefile.config `\n",
        "  - And also as seen [here](https://github.com/BVLC/caffe/issues/3834), the WITH_PYTHON_LAYER has been uncommented in the file `/content/caffe/Make.config`: `!sed -i 's/# WITH_PYTHON_LAYER := 1/WITH_PYTHON_LAYER := 1/' Makefile.config ` \n",
        "  \n",
        " \n",
        "before executing `%cd /content/caffe \\ !make pycaffe` \n",
        "\n"
      ],
      "metadata": {
        "id": "pZQtFznro1sV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "if os.path.isfile(caffe_root + 'models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel'):\n",
        "    print('CaffeNet found.')\n",
        "else:\n",
        "    print('Downloading pre-trained CaffeNet model...')\n",
        "    !/content/caffe/scripts/download_model_binary.py /content/caffe/models/bvlc_reference_caffenet\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgrgvOF3aheq",
        "outputId": "4a16aca6-7207-4e60-9193-20e9655b8d33"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading pre-trained CaffeNet model...\n",
            "...100%, 232 MB, 6141 KB/s, 38 seconds passed"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "caffe.set_mode_cpu()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "Ed35zQyNczcB",
        "outputId": "28521852-1a56-4cbf-b3c9-38505841378f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-46a4bc332b49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcaffe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_mode_cpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: module 'caffe' has no attribute 'set_mode_cpu'"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "RCP209_deeplabv2-test_00_classement-failling_to_import_caffe_lib.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOdShwyVyKUGWAJadjy+UEk",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}